{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"chapter_3_tutorial.ipynb","provenance":[],"authorship_tag":"ABX9TyMe5t1uK0KU73PJTnnCUyMo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Practice Exercises: "],"metadata":{"id":"Kr-M3SfJWaaG"}},{"cell_type":"code","execution_count":193,"metadata":{"id":"xPs2oxmcWQke","executionInfo":{"status":"ok","timestamp":1656029641906,"user_tz":-120,"elapsed":416,"user":{"displayName":"Abdulhabir Karahanli","userId":"08272639422352717475"}}},"outputs":[],"source":["import torch\n","from matplotlib import pyplot as plt\n","import random"]},{"cell_type":"markdown","source":[""],"metadata":{"id":"alsCk5EFWZJ0"}},{"cell_type":"markdown","source":["1.   We construct an artificial dataset according to a linear model\n","( w = [2, − 3.4]⊤ and b = 4.2 ) with normal distributed noise. \n","2.   1000 examples with 2 features sampled from standard normal distribution.\n","\n"],"metadata":{"id":"0WNENwlAXhac"}},{"cell_type":"code","source":["def synthetic_data(w, b, num_examples):\n","  \"\"\"Generate y = Xw + b + noise\"\"\"\n","  X = torch.normal(0, 0.01, (num_examples, len(w)))\n","  y = torch.matmul(X, w) + b \n","  y += torch.normal(0, 0.01, y.shape)\n","  return X, y.reshape((-1, 1))\n","\n","true_w = torch.tensor([2, -3.4])\n","true_b = 4.2\n","\n","features, labels = synthetic_data(true_w, true_b, 1000)"],"metadata":{"id":"WdgkeSNRXEP3","executionInfo":{"status":"ok","timestamp":1656029642266,"user_tz":-120,"elapsed":13,"user":{"displayName":"Abdulhabir Karahanli","userId":"08272639422352717475"}}},"execution_count":194,"outputs":[]},{"cell_type":"code","source":["# Scatter plot of the 2nd feature features[:, 1] and labels.\n","plt.scatter(features[:, (1)].detach().numpy(), labels.detach().numpy(), 1)\n","plt.show()\n","\n","# We observe linear correlation between input and output."],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"SBlIWdhiXES1","executionInfo":{"status":"ok","timestamp":1656029642268,"user_tz":-120,"elapsed":13,"user":{"displayName":"Abdulhabir Karahanli","userId":"08272639422352717475"}},"outputId":"4a9af042-1b07-438a-ff87-ed9c282110d6"},"execution_count":195,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["# Linear Regression \n","### Linear Regression Model\n","\n","To calculate the output of the linear model,\n","we simply take the matrix-vector dot product\n","of the input features $\\mathbf{X}$ and the model weights $\\mathbf{w}$,\n","and add the offset $b$ to each example.\n","Note that below $\\mathbf{Xw}$  is a vector and $b$ is a scalar.\n","Recall the broadcasting mechanism as described in chapter 2.\n","When we add a vector and a scalar,\n","the scalar is added to each component of the vector."],"metadata":{"id":"4I2ed6J05e18"}},{"cell_type":"code","source":["# set up the model\n","def linreg(X, w, b):\n","  \"\"\"The linear regression model\"\"\"\n","  return torch.matmul(X, w) + b"],"metadata":{"id":"reaqFhiYXEV0","executionInfo":{"status":"ok","timestamp":1656029642269,"user_tz":-120,"elapsed":13,"user":{"displayName":"Abdulhabir Karahanli","userId":"08272639422352717475"}}},"execution_count":196,"outputs":[]},{"cell_type":"markdown","source":["### Loss Function\n","\n","Before we start thinking about how to fit data with our model, we need to determine a measure of fitness.\n","The loss function quantifies the distance between the real and predicted value of the target.\n","The loss will usually be a non-negative number where smaller values are better and perfect predictions incur a loss of `0`.\n","The most popular loss function in regression problems is the squared error. \n","\n","Here we will implement the squared loss function in PyTorch.\n","In the implementation, we first need to transform the true value `y` into the predicted value’s shape `y_hat` and compute the squared of the difference with the predicted value. The result returned by the function will also have the same shape as `y_hat`."],"metadata":{"id":"BcYSskbf5krp"}},{"cell_type":"code","source":["# create the loss function: to determinde the measure of fitness, the most popular loss function in linear regression model is the squared error\n","def squared_loss(y_hat, y):\n","  \"\"\"Squared loss.\"\"\"\n","  return (y_hat - y.reshape(y_hat.shape))**2 / 2 \n"],"metadata":{"id":"VKgC2TeVXEYq","executionInfo":{"status":"ok","timestamp":1656029642271,"user_tz":-120,"elapsed":14,"user":{"displayName":"Abdulhabir Karahanli","userId":"08272639422352717475"}}},"execution_count":197,"outputs":[]},{"cell_type":"markdown","source":["### Stochastic Gradient Descent\n","\n","The following code applies the stochastic gradient descent update, given a set of parameters, a learning rate, and a batch size.\n","At each step, using one minibatch randomly drawn from our dataset, we will estimate the gradient of the loss with respect to our parameters. Next, we will update our parameters in the direction that may reduce the loss. The size of the update step is determined by the learning rate `lr`. \n","Because our loss is calculated as a sum over the minibatch of examples, we normalize our step size by the batch size, so that the magnitude of a typical step size does not depend heavily on our choice of the batch size."],"metadata":{"id":"zw8BP7QK5tOv"}},{"cell_type":"code","source":["def sgd(params, lr, batch_size):\n","  \"\"\"Minibatch stochastic gradient descent\"\"\"\n","  with torch.no_grad():\n","    for param in params:\n","      param -= lr * param.grad / batch_size\n","      param.grad.zero_()"],"metadata":{"id":"eRfLwIaMXEbc","executionInfo":{"status":"ok","timestamp":1656029642271,"user_tz":-120,"elapsed":13,"user":{"displayName":"Abdulhabir Karahanli","userId":"08272639422352717475"}}},"execution_count":198,"outputs":[]},{"cell_type":"markdown","source":["### Reading Dataset\n","\n","In the following code, we define the data_iter function to demonstrate a functtion shuffle the dataset and access it in minibatches.\n","The function takes a batch size, a matrix of features, and a vector of labels, yielding minibatches of the size batch_size. Each minibatch consists of a tuple of features and labels."],"metadata":{"id":"CbekJ1ET6tCQ"}},{"cell_type":"code","source":["def data_iter(batch_size, features, labels): \n","  num_examples = len(features)\n","  indices = list(range(num_examples))\n","  \n","  # the examples are read at random, in no particular order\n","  random.shuffle(indices)\n","\n","  for i in range(0, num_examples, batch_size):\n","    batch_indices = torch.tensor(indices[i:min(i + batch_size, num_examples)])\n","    yield features[batch_indices], labels[batch_indices]"],"metadata":{"id":"rKXB3NnQ6bTq","executionInfo":{"status":"ok","timestamp":1656029642272,"user_tz":-120,"elapsed":13,"user":{"displayName":"Abdulhabir Karahanli","userId":"08272639422352717475"}}},"execution_count":199,"outputs":[]},{"cell_type":"markdown","source":["### Model Initialization\n","\n","Before we can begin optimizing our model’s parameters to best fit the our training dataset, we need to have some parameters in the first place.\n","We cannot initialize all weights to the value `0.0`.\n","Initializing all the weights with zeros leads the neurons to learn the same features during training.\n","In the following code, we initialize weights by sampling random numbers from a normal distribution with mean `0` and a standard deviation of `0.01`, and setting the bias to `0`."],"metadata":{"id":"-t_UH0Eb8Cpb"}},{"cell_type":"code","source":["w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)\n","b = torch.zeros(1, requires_grad=True)"],"metadata":{"id":"TZ3mG8xq70Iv","executionInfo":{"status":"ok","timestamp":1656029642272,"user_tz":-120,"elapsed":13,"user":{"displayName":"Abdulhabir Karahanli","userId":"08272639422352717475"}}},"execution_count":200,"outputs":[]},{"cell_type":"markdown","source":["### Model Training\n","\n","In each epoch, we will iterate through the entire dataset once passing through every example in the training dataset.\n","In each iteration, we will grab a minibatch of training examples using the data_iter function we created in the last slide.\n","We the pass the mini batch training examples through our model to obtain a set of predictions. We then compute the loss using the squared_loss function we had implemented earlier. Next we initiate the backwards function to instruct PyTorch to store the gradients of the loss with respect to each parameter.  Finally, we will call the optimization algorithm sgd to update the model parameters.\n","\n"],"metadata":{"id":"dLtz2sPY8oA7"}},{"cell_type":"code","source":["lr = 0.01\n","num_epochs = 3\n","batch_size = 11\n","\n","for epoch in range(num_epochs):\n","    for X, y in data_iter(batch_size, features, labels):\n","        l = squared_loss(linreg(X, w, b), y)  # Minibatch loss in `X` and `y`\n","        # Compute gradient on `l` with respect to [`w`, `b`]\n","        l.sum().backward()\n","        sgd([w, b], lr, batch_size)  # Update parameters using their gradient\n","    with torch.no_grad():\n","        train_l = squared_loss(linreg(features, w, b), labels)\n","        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X0NQbWBa8QTJ","executionInfo":{"status":"ok","timestamp":1656029642591,"user_tz":-120,"elapsed":331,"user":{"displayName":"Abdulhabir Karahanli","userId":"08272639422352717475"}},"outputId":"c1dc1b1e-63d9-4cc0-8728-26bf23f8f805"},"execution_count":201,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 1, loss 1.418756\n","epoch 2, loss 0.229242\n","epoch 3, loss 0.037544\n"]}]},{"cell_type":"markdown","source":["# Single Layer Neural Network"],"metadata":{"id":"lhNk2yN180cg"}},{"cell_type":"markdown","source":["### Neural Network Model\n","\n","In PyTorch, the fully-connected layer is defined in the `Linear` class.\n","Note that we passed two arguments into `nn.Linear`. The first one specifies the input feature dimension, which is `2`.\n","and the second one is the output feature dimension, which is a single scalar and therefore `1`.\n","\n","We then define a model variable `net`, which will refer to an instance of the `Sequential` class. The `Sequential` class defines a container for several layers that will be chained together. "],"metadata":{"id":"x0ynQkU38yqe"}},{"cell_type":"code","source":["from torch import nn \n","from torch.utils import data\n","\n","\n","# model name\n","\n","net = nn.Linear(2,1)"],"metadata":{"id":"q2hU64FL8zwu","executionInfo":{"status":"ok","timestamp":1656029642592,"user_tz":-120,"elapsed":23,"user":{"displayName":"Abdulhabir Karahanli","userId":"08272639422352717475"}}},"execution_count":202,"outputs":[]},{"cell_type":"markdown","source":["### Neural Network Loss\n","\n","The `MSELoss` class from PyTorch computes the mean squared error between each element in the prediction and target.\n","Mean squared error is also sometimes referred to squared L2 norm.\n","By default it returns the average loss over examples."],"metadata":{"id":"EI2ccLSL90ds"}},{"cell_type":"code","source":["loss = nn.MSELoss()"],"metadata":{"id":"KUKPL2sK9g16","executionInfo":{"status":"ok","timestamp":1656029642592,"user_tz":-120,"elapsed":22,"user":{"displayName":"Abdulhabir Karahanli","userId":"08272639422352717475"}}},"execution_count":203,"outputs":[]},{"cell_type":"markdown","source":["### Neural Network Optimization\n","\n","Stochastic gradient descent or SGD for short is a standard tool for optimizing neural networks and thus PyTorch supports it alongside a number of variations on this algorithm in the `optim` module.\n","When we instantiate an SGD instance, we will specify the parameters to optimize over, and which hyperparameters are required by our optimization algorithm. \n","Function `net.parameters()` returns the neural network parameters. Stochastic gradient descent just requires that we set the value learning rate `lr`, which is set to `0.03` here.\n","\n","\n"],"metadata":{"id":"GiYsw_It-Pda"}},{"cell_type":"code","source":["optimizer = torch.optim.SGD(net.parameters(), lr=0.03)"],"metadata":{"id":"mmMjwdlI97c-","executionInfo":{"status":"ok","timestamp":1656029642593,"user_tz":-120,"elapsed":22,"user":{"displayName":"Abdulhabir Karahanli","userId":"08272639422352717475"}}},"execution_count":204,"outputs":[]},{"cell_type":"markdown","source":["### Reading Dataset\n","\n","Rather than creating our own iterator, we can call upon the existing API in a framework to read data.\n","We pass in features and labels as arguments and specify `batch_size` when instantiating a data iterator object. Besides, the boolean value `is_train` indicates whether or not we want the data iterator object to shuffle the data on each epoch.\n","Now we can use `data_iter` in much the same way as we called the `data_iter` function in the linear regression section."],"metadata":{"id":"LjRuLKxM-3jA"}},{"cell_type":"markdown","source":["### Neural Network Model Initialization\n","\n","Before using net, we need to initialize the model parameters, such as the weights and bias in the linear regression model.\n","Deep learning frameworks like PyTorch often have a predefined way to initialize the parameters.\n","Here we specify that each weight parameter should be randomly sampled from a normal distribution with mean `0` and standard deviation `0.01`.\n","The bias parameter will be initialized to zero."],"metadata":{"id":"7waSZ9mM-3Gy"}},{"cell_type":"code","source":["net.weight.data.normal_(0, 0.01)\n","net.bias.data.fill_(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qN-gAVAL-Z_j","executionInfo":{"status":"ok","timestamp":1656029642593,"user_tz":-120,"elapsed":22,"user":{"displayName":"Abdulhabir Karahanli","userId":"08272639422352717475"}},"outputId":"1e967df4-35ad-4cad-eff4-44e03bc01af7"},"execution_count":205,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.])"]},"metadata":{},"execution_count":205}]},{"cell_type":"markdown","source":["## Essential Step:\n","\n","### Neural Network Model Training\n","\n","For some number of epochs which we fix, we will make a complete pass over the dataset, iteratively grabbing one minibatch of inputs and the corresponding ground-truth labels.\n","\n","For each minibatch, we go through the following steps:\n","* Generate predictions by calling `net(X)` and calculate the loss `l` .\n","* Calculate gradients by calling the `l.backward()` function. This step is what is commonly know as the backpropagation step.\n","* Update the model parameters by invoking our `optimizer`."],"metadata":{"id":"qcddD7P6_5TS"}},{"cell_type":"code","source":["num_epochs = 10\n","\n","for epoch in range(num_epochs):\n","  for X, y in data_iter(batch_size, features, labels):\n","    l = loss(net(X), y)\n","    optimizer.zero_grad()\n","    l.backward()\n","    optimizer.step()\n","\n","  l = loss(net(features), labels)\n","  print(f'epoch {epoch + 1}, loss { l:f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"31a_93_E_aFO","executionInfo":{"status":"ok","timestamp":1656029642594,"user_tz":-120,"elapsed":14,"user":{"displayName":"Abdulhabir Karahanli","userId":"08272639422352717475"}},"outputId":"16f2344a-e910-4197-dd6e-a8f2dd986bd6"},"execution_count":206,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 1, loss 0.001843\n","epoch 2, loss 0.001632\n","epoch 3, loss 0.001634\n","epoch 4, loss 0.001631\n","epoch 5, loss 0.001633\n","epoch 6, loss 0.001629\n","epoch 7, loss 0.001631\n","epoch 8, loss 0.001625\n","epoch 9, loss 0.001621\n","epoch 10, loss 0.001620\n"]}]},{"cell_type":"code","source":["# if we do not implimnet optimizer.zero_grad(), our loss will be much larger. As well as the optimizer.step(). "],"metadata":{"id":"DZ9hUHkoA828","executionInfo":{"status":"ok","timestamp":1656029642594,"user_tz":-120,"elapsed":6,"user":{"displayName":"Abdulhabir Karahanli","userId":"08272639422352717475"}}},"execution_count":207,"outputs":[]}]}